# -*- coding: utf-8 -*-
"""virtual_final_image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z1MoDYbM4JUVHvovb-lhRSNi1Q5pOqVH
"""

!pip install opencv-python-headless==4.8.0.76

from IPython import get_ipython
from IPython.display import display
# %%
import cv2
import numpy as np
import torch
from torchvision import models, transforms
from PIL import Image
from google.colab.patches import cv2_imshow # Import cv2_imshow
# %%
# Load DeepLabV3 for background segmentation

deeplab = models.segmentation.deeplabv3_resnet101(pretrained=True).eval()

def segment_background(img):
    """Use DeepLabV3 to extract foreground from an image."""
    # Convert the image to RGB before preprocessing if it has an alpha channel
    if img.shape[2] == 4:  # Check if the image has 4 channels (RGBA)
        img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)  # Convert to RGB

    preprocess = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    img_tensor = preprocess(img).unsqueeze(0)
    with torch.no_grad():
        output = deeplab(img_tensor)["out"][0]

    mask = output.argmax(0).byte().numpy()
    mask_resized = cv2.resize(mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)

    img_rgba = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)
    img_rgba[:, :, 3] = (mask_resized * 255).astype(np.uint8)  # Apply alpha channel based on mask

    return img_rgba
# %%

def get_largest_shape(img):
    """Identify the most significant contour in the processed image."""
    grayscale = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)
    _, binary = cv2.threshold(grayscale, 1, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    return max(contours, key=cv2.contourArea) if contours else None
# %%

def extract_clothing_info(file_path):
    """Detect clothing shape, outline keypoints, and calculate bounding region."""
    img_original = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)
    if img_original is None:
        print("Error: Unable to load the image. Please check the path!")
        return None

    img_processed = segment_background(img_original)
    clothing_contour = get_largest_shape(img_processed)

    if clothing_contour is None:
        print("No distinct shape detected in the image.")
        return None

    # Compute bounding box
    x, y, width, height = cv2.boundingRect(clothing_contour)

    # Approximate key edge points
    tolerance = 0.02 * cv2.arcLength(clothing_contour, True)
    refined_edges = cv2.approxPolyDP(clothing_contour, tolerance, True)
    key_coordinates = [(point[0][0], point[0][1]) for point in refined_edges]

    # Visualization
    output_img = img_processed.copy()
    for coord in key_coordinates:
        cv2.circle(output_img, coord, 5, (0, 255, 0, 255), -1)
    cv2.rectangle(output_img, (x, y), (x + width, y + height), (255, 0, 0, 255), 2)

    # Use cv2_imshow instead of cv2.imshow
    cv2_imshow(cv2.cvtColor(output_img, cv2.COLOR_BGRA2BGR))
 #   cv2.waitKey(0) # These lines are not needed in Colab
 #   cv2.destroyAllWindows()

    return {
        "bounding_box": (x, y, width, height),
        "key_points": key_coordinates
    } # Removed the extra comma here
# Execute the function with an image path
img_path = "/content/testimg6.png"
result = extract_clothing_info(img_path)

if result:
    print("Detected Clothing Bounding Box:", result["bounding_box"])
    print("Key Edge Points:", result["key_points"])